{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG7FW1XaqAuA"
      },
      "outputs": [],
      "source": [
        "#Installing the dependencies\n",
        "!pip install PyPDF2\n",
        "!pip install InstructorEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "La3j4AFCqAuC"
      },
      "outputs": [],
      "source": [
        "#Import necessary Libraries\n",
        "import torch\n",
        "import PyPDF2\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "import pandas as pd\n",
        "import re\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
        "from langchain.chains import (\n",
        "    StuffDocumentsChain, LLMChain, ConversationalRetrievalChain\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RadUSRZ2qAuC"
      },
      "source": [
        "Loading the docs through PyPDFLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaK5iz_aqAuD",
        "outputId": "3edf7255-e0da-43d3-b374-d581b502cebd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['UltimateGuidetoDataScienceInterviews-2.pdf',\n",
              " \"A Beginner's guide to R.pdf\",\n",
              " 'M1-Machine-Learning-Tom-Mitchell.pdf',\n",
              " 'M2-Machine_Learning_By_Ethem_Alpaydin.pdf',\n",
              " 'ML questions_part2.pdf',\n",
              " 'Deep Learning-Ian Goodfellow.pdf',\n",
              " '[Joel_Grus]_Data_Science_from_Scratch_First_Princ.pdf',\n",
              " 'Data Scientist Interview Questions.pdf',\n",
              " 'bigdata-analysis-interview-questions.pdf',\n",
              " 'pythondatasciencehandbook.pdf',\n",
              " 'Python_Machine_Learning_Sebastian_Raschka.pdf',\n",
              " 'thinkstats2.pdf',\n",
              " 'R programming for data science.pdf',\n",
              " 'Handbook_of_Research_on_Emerging_Trends_and_Applications_of_Machine.pdf',\n",
              " 'Think_Like_a_Data_Scientist.pdf',\n",
              " 'Practical_Machine_Learning_with_AWS_Process,_Himanshu Singh.pdf',\n",
              " 'Prediction Machines-The Simple Economics of Artificial Intelligence by Ajay Agrawal.pdf',\n",
              " 'python_interview_questions.pdf',\n",
              " 'Advanced Applied Deep Learning-Umberto Michelucci.pdf',\n",
              " 'Python for Data Analysis.pdf',\n",
              " 'Hands-on-Machine-Learning.pdf']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "path = '/Users/srikar/Documents/DSRag/data'\n",
        "os.listdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Tv-AS7iqAuE",
        "outputId": "c1be8215-bfb2-45fc-d0e4-050cdfb6b1b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 10/21 [01:00<00:52,  4.79s/it]Ignoring wrong pointing object 3268 0 (offset 0)\n",
            "Ignoring wrong pointing object 3269 0 (offset 0)\n",
            "Ignoring wrong pointing object 5594 0 (offset 0)\n",
            "Ignoring wrong pointing object 5595 0 (offset 0)\n",
            "Ignoring wrong pointing object 5596 0 (offset 0)\n",
            "Ignoring wrong pointing object 5597 0 (offset 0)\n",
            "Ignoring wrong pointing object 5598 0 (offset 0)\n",
            "Ignoring wrong pointing object 5599 0 (offset 0)\n",
            "Ignoring wrong pointing object 5600 0 (offset 0)\n",
            "Ignoring wrong pointing object 5601 0 (offset 0)\n",
            "Ignoring wrong pointing object 5602 0 (offset 0)\n",
            "Ignoring wrong pointing object 5603 0 (offset 0)\n",
            "Ignoring wrong pointing object 5604 0 (offset 0)\n",
            "Ignoring wrong pointing object 5605 0 (offset 0)\n",
            "Ignoring wrong pointing object 5606 0 (offset 0)\n",
            "Ignoring wrong pointing object 5607 0 (offset 0)\n",
            "Ignoring wrong pointing object 5608 0 (offset 0)\n",
            "Ignoring wrong pointing object 5609 0 (offset 0)\n",
            "Ignoring wrong pointing object 5610 0 (offset 0)\n",
            "Ignoring wrong pointing object 5611 0 (offset 0)\n",
            "Ignoring wrong pointing object 5612 0 (offset 0)\n",
            "Ignoring wrong pointing object 5613 0 (offset 0)\n",
            "Ignoring wrong pointing object 5614 0 (offset 0)\n",
            "Ignoring wrong pointing object 5615 0 (offset 0)\n",
            "Ignoring wrong pointing object 5616 0 (offset 0)\n",
            "Ignoring wrong pointing object 5617 0 (offset 0)\n",
            "Ignoring wrong pointing object 5618 0 (offset 0)\n",
            "Ignoring wrong pointing object 5619 0 (offset 0)\n",
            "Ignoring wrong pointing object 5620 0 (offset 0)\n",
            "Ignoring wrong pointing object 5621 0 (offset 0)\n",
            "Ignoring wrong pointing object 5622 0 (offset 0)\n",
            "Ignoring wrong pointing object 5623 0 (offset 0)\n",
            "Ignoring wrong pointing object 5624 0 (offset 0)\n",
            "Ignoring wrong pointing object 5625 0 (offset 0)\n",
            "Ignoring wrong pointing object 5626 0 (offset 0)\n",
            "Ignoring wrong pointing object 5627 0 (offset 0)\n",
            "Ignoring wrong pointing object 5628 0 (offset 0)\n",
            "Ignoring wrong pointing object 5629 0 (offset 0)\n",
            "Ignoring wrong pointing object 5630 0 (offset 0)\n",
            "Ignoring wrong pointing object 5631 0 (offset 0)\n",
            "Ignoring wrong pointing object 5632 0 (offset 0)\n",
            "Ignoring wrong pointing object 5633 0 (offset 0)\n",
            "Ignoring wrong pointing object 5634 0 (offset 0)\n",
            "Ignoring wrong pointing object 5635 0 (offset 0)\n",
            "Ignoring wrong pointing object 5636 0 (offset 0)\n",
            "Ignoring wrong pointing object 5637 0 (offset 0)\n",
            "Ignoring wrong pointing object 5638 0 (offset 0)\n",
            "Ignoring wrong pointing object 5639 0 (offset 0)\n",
            "Ignoring wrong pointing object 5640 0 (offset 0)\n",
            "Ignoring wrong pointing object 5641 0 (offset 0)\n",
            "Ignoring wrong pointing object 5642 0 (offset 0)\n",
            "Ignoring wrong pointing object 5643 0 (offset 0)\n",
            "Ignoring wrong pointing object 6025 0 (offset 0)\n",
            "Ignoring wrong pointing object 6026 0 (offset 0)\n",
            "Ignoring wrong pointing object 6027 0 (offset 0)\n",
            "Ignoring wrong pointing object 6028 0 (offset 0)\n",
            "Ignoring wrong pointing object 6029 0 (offset 0)\n",
            "Ignoring wrong pointing object 6030 0 (offset 0)\n",
            "Ignoring wrong pointing object 6031 0 (offset 0)\n",
            "Ignoring wrong pointing object 6032 0 (offset 0)\n",
            "Ignoring wrong pointing object 6033 0 (offset 0)\n",
            "Ignoring wrong pointing object 6034 0 (offset 0)\n",
            "Ignoring wrong pointing object 6035 0 (offset 0)\n",
            "Ignoring wrong pointing object 6036 0 (offset 0)\n",
            "Ignoring wrong pointing object 6037 0 (offset 0)\n",
            "Ignoring wrong pointing object 6038 0 (offset 0)\n",
            "Ignoring wrong pointing object 6039 0 (offset 0)\n",
            "Ignoring wrong pointing object 6040 0 (offset 0)\n",
            "Ignoring wrong pointing object 6041 0 (offset 0)\n",
            "Ignoring wrong pointing object 6042 0 (offset 0)\n",
            "Ignoring wrong pointing object 6043 0 (offset 0)\n",
            "Ignoring wrong pointing object 6044 0 (offset 0)\n",
            "Ignoring wrong pointing object 6045 0 (offset 0)\n",
            "Ignoring wrong pointing object 6046 0 (offset 0)\n",
            "Ignoring wrong pointing object 6047 0 (offset 0)\n",
            "Ignoring wrong pointing object 6048 0 (offset 0)\n",
            "Ignoring wrong pointing object 6049 0 (offset 0)\n",
            "Ignoring wrong pointing object 6050 0 (offset 0)\n",
            "Ignoring wrong pointing object 6051 0 (offset 0)\n",
            "Ignoring wrong pointing object 6052 0 (offset 0)\n",
            "Ignoring wrong pointing object 6053 0 (offset 0)\n",
            "Ignoring wrong pointing object 6054 0 (offset 0)\n",
            "Ignoring wrong pointing object 6055 0 (offset 0)\n",
            "Ignoring wrong pointing object 6056 0 (offset 0)\n",
            "Ignoring wrong pointing object 6057 0 (offset 0)\n",
            "Ignoring wrong pointing object 6058 0 (offset 0)\n",
            "Ignoring wrong pointing object 6059 0 (offset 0)\n",
            "Ignoring wrong pointing object 6060 0 (offset 0)\n",
            "Ignoring wrong pointing object 6061 0 (offset 0)\n",
            "Ignoring wrong pointing object 6062 0 (offset 0)\n",
            "Ignoring wrong pointing object 6063 0 (offset 0)\n",
            "Ignoring wrong pointing object 6064 0 (offset 0)\n",
            "Ignoring wrong pointing object 6065 0 (offset 0)\n",
            "Ignoring wrong pointing object 6066 0 (offset 0)\n",
            "Ignoring wrong pointing object 6067 0 (offset 0)\n",
            "Ignoring wrong pointing object 6068 0 (offset 0)\n",
            "Ignoring wrong pointing object 6069 0 (offset 0)\n",
            "Ignoring wrong pointing object 6070 0 (offset 0)\n",
            "Ignoring wrong pointing object 6071 0 (offset 0)\n",
            "Ignoring wrong pointing object 6072 0 (offset 0)\n",
            "Ignoring wrong pointing object 6073 0 (offset 0)\n",
            "Ignoring wrong pointing object 6074 0 (offset 0)\n",
            "Ignoring wrong pointing object 6075 0 (offset 0)\n",
            "Ignoring wrong pointing object 6076 0 (offset 0)\n",
            "Ignoring wrong pointing object 6077 0 (offset 0)\n",
            "Ignoring wrong pointing object 6078 0 (offset 0)\n",
            "Ignoring wrong pointing object 6079 0 (offset 0)\n",
            "Ignoring wrong pointing object 6080 0 (offset 0)\n",
            "Ignoring wrong pointing object 6081 0 (offset 0)\n",
            "Ignoring wrong pointing object 6082 0 (offset 0)\n",
            "Ignoring wrong pointing object 6083 0 (offset 0)\n",
            "Ignoring wrong pointing object 6084 0 (offset 0)\n",
            "Ignoring wrong pointing object 6085 0 (offset 0)\n",
            "Ignoring wrong pointing object 6086 0 (offset 0)\n",
            "Ignoring wrong pointing object 6087 0 (offset 0)\n",
            "Ignoring wrong pointing object 6088 0 (offset 0)\n",
            "Ignoring wrong pointing object 6089 0 (offset 0)\n",
            "Ignoring wrong pointing object 6090 0 (offset 0)\n",
            "Ignoring wrong pointing object 6091 0 (offset 0)\n",
            "Ignoring wrong pointing object 6092 0 (offset 0)\n",
            "Ignoring wrong pointing object 6093 0 (offset 0)\n",
            "Ignoring wrong pointing object 6094 0 (offset 0)\n",
            "Ignoring wrong pointing object 6095 0 (offset 0)\n",
            "Ignoring wrong pointing object 6096 0 (offset 0)\n",
            "Ignoring wrong pointing object 6097 0 (offset 0)\n",
            "Ignoring wrong pointing object 6098 0 (offset 0)\n",
            "Ignoring wrong pointing object 6099 0 (offset 0)\n",
            "Ignoring wrong pointing object 6100 0 (offset 0)\n",
            "Ignoring wrong pointing object 6101 0 (offset 0)\n",
            "Ignoring wrong pointing object 6102 0 (offset 0)\n",
            "Ignoring wrong pointing object 6103 0 (offset 0)\n",
            "Ignoring wrong pointing object 6104 0 (offset 0)\n",
            "Ignoring wrong pointing object 6105 0 (offset 0)\n",
            "Ignoring wrong pointing object 6106 0 (offset 0)\n",
            "Ignoring wrong pointing object 6107 0 (offset 0)\n",
            "Ignoring wrong pointing object 6108 0 (offset 0)\n",
            "Ignoring wrong pointing object 6109 0 (offset 0)\n",
            "Ignoring wrong pointing object 6110 0 (offset 0)\n",
            "Ignoring wrong pointing object 6111 0 (offset 0)\n",
            "Ignoring wrong pointing object 6112 0 (offset 0)\n",
            "Ignoring wrong pointing object 6113 0 (offset 0)\n",
            "Ignoring wrong pointing object 6114 0 (offset 0)\n",
            "Ignoring wrong pointing object 6115 0 (offset 0)\n",
            "Ignoring wrong pointing object 6116 0 (offset 0)\n",
            "Ignoring wrong pointing object 6117 0 (offset 0)\n",
            "Ignoring wrong pointing object 6118 0 (offset 0)\n",
            "Ignoring wrong pointing object 6119 0 (offset 0)\n",
            "Ignoring wrong pointing object 6120 0 (offset 0)\n",
            "Ignoring wrong pointing object 6121 0 (offset 0)\n",
            "Ignoring wrong pointing object 6122 0 (offset 0)\n",
            "Ignoring wrong pointing object 6123 0 (offset 0)\n",
            "Ignoring wrong pointing object 6124 0 (offset 0)\n",
            "Ignoring wrong pointing object 6125 0 (offset 0)\n",
            "Ignoring wrong pointing object 6126 0 (offset 0)\n",
            "Ignoring wrong pointing object 6127 0 (offset 0)\n",
            "Ignoring wrong pointing object 6128 0 (offset 0)\n",
            "Ignoring wrong pointing object 6129 0 (offset 0)\n",
            "Ignoring wrong pointing object 6130 0 (offset 0)\n",
            "Ignoring wrong pointing object 6131 0 (offset 0)\n",
            "Ignoring wrong pointing object 6132 0 (offset 0)\n",
            "Ignoring wrong pointing object 6133 0 (offset 0)\n",
            "Ignoring wrong pointing object 6134 0 (offset 0)\n",
            "Ignoring wrong pointing object 6135 0 (offset 0)\n",
            "Ignoring wrong pointing object 6136 0 (offset 0)\n",
            "Ignoring wrong pointing object 6137 0 (offset 0)\n",
            "Ignoring wrong pointing object 6138 0 (offset 0)\n",
            "Ignoring wrong pointing object 6139 0 (offset 0)\n",
            "Ignoring wrong pointing object 6140 0 (offset 0)\n",
            "Ignoring wrong pointing object 6141 0 (offset 0)\n",
            "Ignoring wrong pointing object 6142 0 (offset 0)\n",
            "Ignoring wrong pointing object 6143 0 (offset 0)\n",
            "Ignoring wrong pointing object 6144 0 (offset 0)\n",
            "Ignoring wrong pointing object 6145 0 (offset 0)\n",
            "Ignoring wrong pointing object 6146 0 (offset 0)\n",
            "Ignoring wrong pointing object 6147 0 (offset 0)\n",
            "Ignoring wrong pointing object 6148 0 (offset 0)\n",
            "Ignoring wrong pointing object 6149 0 (offset 0)\n",
            "Ignoring wrong pointing object 6150 0 (offset 0)\n",
            "Ignoring wrong pointing object 6151 0 (offset 0)\n",
            "Ignoring wrong pointing object 6152 0 (offset 0)\n",
            "Ignoring wrong pointing object 6153 0 (offset 0)\n",
            "Ignoring wrong pointing object 6154 0 (offset 0)\n",
            "Ignoring wrong pointing object 6155 0 (offset 0)\n",
            "Ignoring wrong pointing object 6156 0 (offset 0)\n",
            "Ignoring wrong pointing object 6157 0 (offset 0)\n",
            "Ignoring wrong pointing object 6158 0 (offset 0)\n",
            "Ignoring wrong pointing object 6159 0 (offset 0)\n",
            "Ignoring wrong pointing object 6168 0 (offset 0)\n",
            "Ignoring wrong pointing object 19721 0 (offset 0)\n",
            "Ignoring wrong pointing object 19730 0 (offset 0)\n",
            "Ignoring wrong pointing object 19731 0 (offset 0)\n",
            "100%|██████████| 21/21 [01:28<00:00,  4.20s/it]\n"
          ]
        }
      ],
      "source": [
        "l= list()\n",
        "for i in os.listdir(path):\n",
        "    l.append(PyPDFLoader(os.path.join(path,i)))\n",
        "\n",
        "\n",
        "docs = []\n",
        "for loader in tqdm(l):\n",
        "    docs.append(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1En_72kqAuE",
        "outputId": "a5c10db2-58f6-482f-c2c1-4bbfef65760f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\xa0\\nTable of Contents \\n\\xa0\\nTable\\xa0of\\xa0Contents\\xa0\\nIntroduction\\xa0\\nWhat\\xa0is\\xa0Data\\xa0Science?\\xa0\\nDifferent\\xa0Roles\\xa0within\\xa0Data\\xa0Science\\xa0\\nHow\\xa0Different\\xa0Companies\\xa0Think\\xa0About\\xa0Data\\xa0Science\\xa0\\n1\\xad\\xa0Early\\xadstage\\xa0startups\\xa0(200\\xa0employees\\xa0or\\xa0fewer)\\xa0looking\\xa0to\\xa0build\\xa0a\\xa0data\\xa0product\\xa0\\n2\\xad\\xa0Early\\xadstage\\xa0startups\\xa0(200\\xa0employees\\xa0or\\xa0fewer)\\xa0looking\\xa0to\\xa0take\\xa0advantage\\xa0of\\xa0their\\xa0data\\xa0\\n3\\xad\\xa0Mid\\xadsize\\xa0and\\xa0large\\xa0Fortune\\xa0500\\xa0companies\\xa0who\\xa0are\\xa0looking\\xa0to\\xa0take\\xa0advantage\\xa0of\\xa0their\\xa0\\ndata\\xa0\\n4\\xad\\xa0Large\\xa0technology\\xa0companies\\xa0with\\xa0well\\xadestablished\\xa0data\\xa0teams\\xa0\\nIndustries\\xa0that\\xa0employ\\xa0Data\\xa0Scientists\\xa0\\nGetting\\xa0a\\xa0Data\\xa0Science\\xa0Interview\\xa0\\nNine\\xa0Paths\\xa0to\\xa0a\\xa0Data\\xa0Science\\xa0Interview\\xa0\\nTraditional\\xa0Paths\\xa0to\\xa0Job\\xa0Interviews\\xa0\\n1\\xad\\xa0Data\\xa0Science\\xa0Job\\xa0Boards\\xa0and\\xa0Standard\\xa0Job\\xa0Applications\\xa0\\n2\\xad\\xa0Work\\xa0with\\xa0a\\xa0Recruiter\\xa0\\n3\\xad\\xa0Go\\xa0to\\xa0Job\\xa0Fairs\\xa0\\nProactive\\xa0Paths\\xa0to\\xa0Job\\xa0Interviews\\xa0\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\u200b4\\xadAttend\\xa0or\\xa0Organize\\xa0a\\xa0Data\\xa0Science\\xa0Event\\xa0\\n5\\u200b\\xad\\xa0\\u200bFreelance\\xa0and\\xa0Build\\xa0a\\xa0Portfolio\\xa0\\n6\\u200b\\xad\\xa0G\\u200bet\\xa0Involved\\xa0in\\xa0Open\\xa0Data\\xa0and\\xa0Open\\xa0Source\\xa0\\n7\\xadParticipate\\xa0in\\xa0Data\\xa0Science\\xa0Competitions\\xa0\\n8\\xadAsk\\xa0for\\xa0Coffees,\\xa0do\\xa0Informational\\xa0Interviews\\xa0\\n9\\xadAttend\\xa0Data\\xa0Hackathons\\xa0\\nWorking\\xa0with\\xa0Recruiters\\xa0\\nHow\\xa0to\\xa0Apply\\xa0\\nCV\\xa0vs\\xa0LinkedIn\\xa0\\nCover\\xa0Letter\\xa0vs\\xa0Email\\xa0\\n \\n \\nwww.springboard.com ULTIMATE GUIDE TO DATA SCIENCE INTERVIEWS 1 \\n \\n'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0][1].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9WjS6u7qAuE"
      },
      "source": [
        "Chunking Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjBxROCoqAuE"
      },
      "outputs": [],
      "source": [
        "doc_splits = list()\n",
        "# split the documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50,\n",
        "    length_function=len,\n",
        ")\n",
        "for doc in docs:\n",
        "    doc_splits.extend(text_splitter.split_documents(doc))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zAVTNBjqAuE"
      },
      "outputs": [],
      "source": [
        "for i in range(len(doc_splits)):\n",
        "    doc_splits[i].page_content = doc_splits[i].page_content.replace(u'\\xa0',u' ')\n",
        "    doc_splits[i].page_content = doc_splits[i].page_content.replace(u'\\xad',u'-')\n",
        "    doc_splits[i].page_content = doc_splits[i].page_content.replace('\\u200b','*')\n",
        "    doc_splits[i].page_content = doc_splits[i].page_content.replace('\\n','')\n",
        "    doc_splits[i].page_content = doc_splits[i].page_content.replace('\\*','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ968f_OqAuF",
        "outputId": "87e6280b-109c-45c8-e46a-421306ee2635"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created 32,561 splits\n"
          ]
        }
      ],
      "source": [
        "for idx, split in enumerate(doc_splits):\n",
        "    split.metadata[\"chunk\"] = idx\n",
        "\n",
        "print(f'Created {len(doc_splits):,} splits')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YYR5QlXqAuF"
      },
      "source": [
        "Display output of a chunk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghyfyp5SqAuF",
        "outputId": "d89ba5d2-2e5d-4c85-be27-1eff9bf227dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='Table of Contents  Table of Contents Introduction What is Data Science? Different Roles within Data Science How Different Companies Think About Data Science 1- Early-stage startups (200 employees or fewer) looking to build a data product 2- Early-stage startups (200 employees or fewer) looking to take advantage of their data 3- Mid-size and large Fortune 500 companies who are looking to take advantage of their data 4- Large technology companies with well-established data teams', metadata={'source': '/Users/ashmitamukherjee/Documents/NvidiaRag/data/UltimateGuidetoDataScienceInterviews-2.pdf', 'page': 1, 'chunk': 0})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_splits[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7OvVyK6qAuF",
        "outputId": "269a0b7d-22c4-4733-93b3-51d5459de106"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Table of Contents  Table of Contents Introduction What is Data Science? Different Roles within Data Science How Different Companies Think About Data Science 1- Early-stage startups (200 employees or fewer) looking to build a data product 2- Early-stage startups (200 employees or fewer) looking to take advantage of their data 3- Mid-size and large Fortune 500 companies who are looking to take advantage of their data 4- Large technology companies with well-established data teams'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_splits[0].page_content\n",
        "#[f'content:-{doc.page_content} metadata:-{doc.metadata}'for doc in doc_splits]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WpROiWrqAuF"
      },
      "source": [
        "Using Instruct Embeddings from HuggingFace for embedding the documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCW3WIvPqAuF",
        "outputId": "15130b55-e3f8-4a51-92c1-6791e64c701d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/InstructorEmbedding/instructor.py:278: UserWarning: MPS: no support for int64 for sum_out_mps, downcasting to a smaller data type (int32/float32). Native support for int64 has been added in macOS 13.3. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:157.)\n",
            "  assert torch.sum(attention_mask[local_idx]).item() >= context_masks[local_idx].item(),\\\n",
            "Ingesting documents: 100%|██████████| 32560/32560 [3:30:24<00:00,  2.58it/s]  \n"
          ]
        }
      ],
      "source": [
        "embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\",model_kwargs = {'device': 'mps'},embed_instruction=\"These Documents will be used in a Question Answering context for an Educational Tool. Embed Accordingly.\")\n",
        "db = FAISS.from_documents([doc_splits[0]], embeddings)\n",
        "with tqdm(total=len(doc_splits)-1, desc=\"Ingesting documents\") as pbar:\n",
        "    for doc in doc_splits[1:]:\n",
        "            db.add_documents([doc])\n",
        "            pbar.update(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On-R4S5_qAuF"
      },
      "source": [
        "Saving and reloading the vector database to check if the embeddings are preserved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FE6OmgGIqAuF"
      },
      "outputs": [],
      "source": [
        "db.save_local(\"faiss_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6ba75fgqAuF"
      },
      "outputs": [],
      "source": [
        "new_db = FAISS.load_local(\"faiss_index\", embeddings,allow_dangerous_deserialization=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XTLSI_8qAuF"
      },
      "source": [
        "Using Llama3 through Ollama as the LLM for this RAG prcoess. I wanted to use open source + locally run LLM for this project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YT1XqmgqAuF"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms import Ollama\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "llm = Ollama(\n",
        "    model=\"llama3\",\n",
        "    callback_manager=CallbackManager(\n",
        "            [StreamingStdOutCallbackHandler()]\n",
        "),\n",
        "    repeat_penalty=1.15,\n",
        "    stop=[\"<|eot_id|>\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxCZM0MlqAuG"
      },
      "source": [
        "SImilarity Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOTIvIeYqAuG",
        "outputId": "fbf94545-538a-463d-8eb2-789dd7e0fd5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most relevant content: import numpy as npIntroducing k-MeansThe k-means algorithm searches for a predetermined number of clusters within anunlabeled multidimensional dataset. It accomplishes this using a simple conception ofwhat the optimal clustering looks like:•The “cluster center” is the arithmetic mean of all the points belonging to thecluster.•Each point is closer to its own cluster center than to other cluster centers. \n",
            " in file: /Users/ashmitamukherjee/Documents/NvidiaRag/data/pythondatasciencehandbook.pdf \n",
            " on page: 480\n"
          ]
        }
      ],
      "source": [
        "query = 'What the K-means algorithm?'\n",
        "docs = db.similarity_search(query)\n",
        "\n",
        "page_content = docs[1].page_content.replace('\\n', ' ')\n",
        "source = docs[1].metadata['source']\n",
        "page = docs[1].metadata['page']\n",
        "\n",
        "\n",
        "print(f'Most relevant content: {page_content} \\n in file: {source} \\n on page: {page}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQuSGzRrqAuG",
        "outputId": "c1992c7c-488f-4c0c-eede-ecfe1bec9c99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found most relevant content in file: /Users/ashmitamukherjee/Documents/NvidiaRag/data/Hands-on-Machine-Learning.pdf on page: 144 \n",
            "\n",
            "According to the context, Gradient Descent is a generic optimization algorithm that iteratively tweaks parameters to minimize a cost function by moving in the direction of the steepest descent along the error surface. It measures the local gradient of the error function with regards to the parameter vector and updates the parameters in the opposite direction of the gradient.According to the context, Gradient Descent is a generic optimization algorithm that iteratively tweaks parameters to minimize a cost function by moving in the direction of the steepest descent along the error surface. It measures the local gradient of the error function with regards to the parameter vector and updates the parameters in the opposite direction of the gradient.\n"
          ]
        }
      ],
      "source": [
        "query = 'what is the meaning of gradient descent?'\n",
        "prompt = query\n",
        "chain = load_qa_chain(\n",
        "    llm,\n",
        "    chain_type=\"stuff\")\n",
        "\n",
        "docs = db.similarity_search(query)\n",
        "source = docs[0].metadata['source']\n",
        "page = docs[0].metadata['page']\n",
        "print(f'Found most relevant content in file: {source} on page: {page} \\n')\n",
        "\n",
        "response = chain.run(input_documents=docs, question=prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-JCEAHFqAuG"
      },
      "source": [
        "Map Reduce Chain - Did not perform well. Reason : It is better at summarization tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSpFPThYqAuH",
        "outputId": "8b9aaca6-a5d4-4551-b2cb-28995db4e92e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You've provided a snippet from a document!\n",
            "\n",
            "According to your request, I'll search for relevant text within this portion of the document regarding \"How to perform linear regression?\"\n",
            "\n",
            "Here's what I found:\n",
            "\n",
            "\"Figure 5-43. A linear regression modelIn Depth: Linear Regression | 391\n",
            "Question: How to perform linear regression?\n",
            "Relevant text, if any:\"\n",
            "\n",
            "Unfortunately, there isn't any relevant text provided in this snippet. The question is asked, but no answer or relevant information is given.\n",
            "\n",
            "If you'd like me to help with anything else or search the surrounding context for answers, feel free to ask!The relevant text is:\n",
            "\n",
            "We will start with the most familiar linear regression, a straight-line fit to data. Astraight-line fit is a model of the form y = ax + b where a is commonly known as the slope, and b is commonly known as the intercept.\n",
            "\n",
            "This section explains the concept of simple linear regression and provides an example.Let's dive in!\n",
            "\n",
            "According to the provided text, here's the relevant information on how to perform linear regression:\n",
            "\n",
            "\"Not applicable\" (since there is no relevant text provided)\n",
            "\n",
            "If you'd like me to help with anything else or clarify the question, feel free to ask!Here is the relevant text:\n",
            "\n",
            "\"Return all relevant text to the question asked.\n",
            "\n",
            "regression.If the relationship between the dependent and explanatory variable is linear, that’s linear regression . For example, if the dependent variable is yandthe explanatory variables are x1andx2, we would write the following linear regression model:y=β0+β1x1+β2x2+εwhereβ0is the intercept, β1is the parameter associated with x1,β2is theparameter associated with x2, andεis the residual due to random variationor other unknown factors.\n",
            "\n",
            "Question: How to perform linear regression?\n",
            "Relevant text, if any:\n",
            "\n",
            "To perform linear regression:\n",
            "y=β0+β1x1+β2x2+ε\"\n",
            "\n",
            "The relevant text is:\n",
            "\n",
            "\"y=β0+β1x1+β2x2+ε\"\n",
            "\n",
            "This text describes the model and provides the formula for performing linear regression.Based on the provided document snippet, it is impossible to answer the question \"How to perform linear regression?\" as there is no relevant text provided.\n",
            "\n",
            "SOURCES:\n",
            "/Users/ashmitamukherjee/Documents/NvidiaRag/data/pythondatasciencehandbook.pdf\n",
            "/Users/ashmitamukherjee/Documents/NvidiaRag/data/thinkstats2.pdfStep #0\n",
            "You've provided a snippet from a document!\n",
            "\n",
            "According to your request, I'll search for relevant text within this portion of the document regarding \"How to perform linear regression?\"\n",
            "\n",
            "Here's what I found:\n",
            "\n",
            "\"Figure 5-43. A linear regression modelIn Depth: Linear Regression | 391\n",
            "Question: How to perform linear regression?\n",
            "Relevant text, if any:\"\n",
            "\n",
            "Unfortunately, there isn't any relevant text provided in this snippet. The question is asked, but no answer or relevant information is given.\n",
            "\n",
            "If you'd like me to help with anything else or search the surrounding context for answers, feel free to ask!\n",
            "\n",
            "\n",
            "Step #1\n",
            "The relevant text is:\n",
            "\n",
            "We will start with the most familiar linear regression, a straight-line fit to data. Astraight-line fit is a model of the form y = ax + b where a is commonly known as the slope, and b is commonly known as the intercept.\n",
            "\n",
            "This section explains the concept of simple linear regression and provides an example.\n",
            "\n",
            "\n",
            "Step #2\n",
            "Let's dive in!\n",
            "\n",
            "According to the provided text, here's the relevant information on how to perform linear regression:\n",
            "\n",
            "\"Not applicable\" (since there is no relevant text provided)\n",
            "\n",
            "If you'd like me to help with anything else or clarify the question, feel free to ask!\n",
            "\n",
            "\n",
            "Step #3\n",
            "Here is the relevant text:\n",
            "\n",
            "\"Return all relevant text to the question asked.\n",
            "\n",
            "regression.If the relationship between the dependent and explanatory variable is linear, that’s linear regression . For example, if the dependent variable is yandthe explanatory variables are x1andx2, we would write the following linear regression model:y=β0+β1x1+β2x2+εwhereβ0is the intercept, β1is the parameter associated with x1,β2is theparameter associated with x2, andεis the residual due to random variationor other unknown factors.\n",
            "\n",
            "Question: How to perform linear regression?\n",
            "Relevant text, if any:\n",
            "\n",
            "To perform linear regression:\n",
            "y=β0+β1x1+β2x2+ε\"\n",
            "\n",
            "The relevant text is:\n",
            "\n",
            "\"y=β0+β1x1+β2x2+ε\"\n",
            "\n",
            "This text describes the model and provides the formula for performing linear regression.\n",
            "\n",
            "\n",
            "FINAL OUTPUT: Based on the provided document snippet, it is impossible to answer the question \"How to perform linear regression?\" as there is no relevant text provided.\n",
            "\n",
            "SOURCES:\n",
            "/Users/ashmitamukherjee/Documents/NvidiaRag/data/pythondatasciencehandbook.pdf\n",
            "/Users/ashmitamukherjee/Documents/NvidiaRag/data/thinkstats2.pdf\n"
          ]
        }
      ],
      "source": [
        "question_prompt_template = \"\"\"Use the following portion of a long document to see if any of the text is relevant to answer the question.\n",
        "Return all relevant text to the question asked.\n",
        "{context}\n",
        "Question: {question}\n",
        "Relevant text, if any:\"\"\"\n",
        "\n",
        "question_prompt = PromptTemplate(\n",
        "    template=question_prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "combine_prompt_template = \"\"\"Given the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\").\n",
        "If the information is not found in the document that was provided, indicate it is impossible to answer based on provided information,\n",
        "abstain from answering and do not provide any document summary.\n",
        "ALWAYS return a \"SOURCES\" part in your answer.\n",
        "\n",
        "# QUESTION: {question}\n",
        "# =========\n",
        "# {summaries}\n",
        "# =========\n",
        "# FINAL ANSWER:\"\"\"\n",
        "\n",
        "combine_prompt = PromptTemplate(\n",
        "    template=combine_prompt_template, input_variables=[\"summaries\", \"question\"]\n",
        ")\n",
        "\n",
        "query = 'How to perform linear regression?'\n",
        "\n",
        "chain = load_qa_with_sources_chain(\n",
        "    llm,\n",
        "    chain_type=\"map_reduce\",\n",
        "    return_intermediate_steps=True,\n",
        "    question_prompt=question_prompt,\n",
        "    combine_prompt=combine_prompt)\n",
        "\n",
        "docs = db.similarity_search(query)\n",
        "\n",
        "response = chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)\n",
        "\n",
        "for n,item in enumerate(response['intermediate_steps']):\n",
        "    print(f'Step #{n}')\n",
        "    print(item)\n",
        "    print('\\n')\n",
        "\n",
        "print(f'FINAL OUTPUT: {response[\"output_text\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO4UdPfsqAuH"
      },
      "source": [
        "Refine Chain - Best performing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpRscMqqqAuH",
        "outputId": "88267f5e-f146-4687-f770-1482443ac8bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the provided context information, we can infer that the output layer of a neural network is capable of modeling complex distributions, including mixtures of Gaussian distributions. The text mentions that the neural network is able to learn non-linear mappings from the input to the parameters of the output distribution, which includes probabilities governing which mixture component will generate the output as well as the parameters for each mixture component.\n",
            "\n",
            "This suggests that neural networks can model a wide range of distributions, including those with complex structures and multimodalities. In particular, the ability to learn the mixture proportions and component parameters allows the network to capture complex patterns in the data.\n",
            "\n",
            "While it is possible to model some distributions using simple statistical models (e.g., normal or exponential), more complex distributions require more advanced modeling techniques. Neural networks have been shown to be capable of modeling a wide range of distributions, including those that are non-parametric and continuous.\n",
            "\n",
            "Therefore, based on the provided context information, we can conclude that neural networks are able to model any distribution.Based on the additional context, we can refine our previous answer to provide a more comprehensive explanation.\n",
            "\n",
            "The original answer stated that neural networks can model complex distributions, including mixtures of Gaussian distributions. However, the new context provides insight into Bayesian networks, which are a type of probabilistic graphical model.\n",
            "\n",
            "A Bayesian network is a directed acyclic graph (DAG) where each node represents a random variable and the edges represent conditional dependencies between variables. Given observed values for only a subset of the other variables, a Bayesian network can be used to compute the probability distribution for any subset of network variables.\n",
            "\n",
            "In the context of modeling distributions, Bayesian networks are particularly useful when dealing with complex, multi-dimensional distributions or conditional probabilities. They allow us to model complex patterns in the data and make probabilistic predictions given some observed values.\n",
            "\n",
            "Neural networks, as we previously established, can also model a wide range of distributions, including non-parametric and continuous ones. However, Bayesian networks offer an additional layer of sophistication in modeling complex dependencies between variables.\n",
            "\n",
            "In light of this new context, we can update our original answer to conclude that neural networks and Bayesian networks are both capable of modeling any distribution. Neural networks can learn complex mappings from input to output distributions, while Bayesian networks provide a powerful framework for modeling conditional probabilities and complex patterns in data.\n",
            "\n",
            "Sources:\n",
            "\n",
            "* Mitchell, T. (2020). Machine Learning. Chapter 6: Bayesian Networks.\n",
            "* The original sources provided earlier remain relevant as well.\n",
            "\n",
            "Final Answer: Neural networks and Bayesian networks are both capable of modeling any distribution.Based on the additional context provided, I refined the original answer to provide a more comprehensive explanation.\n",
            "\n",
            "The original answer stated that neural networks can model complex distributions, including mixtures of Gaussian distributions. However, the new context provides insight into Bayesian networks, which are a type of probabilistic graphical model.\n",
            "\n",
            "A Bayesian network is a directed acyclic graph (DAG) where each node represents a random variable and the edges represent conditional dependencies between variables. Given observed values for only a subset of the other variables, a Bayesian network can be used to compute the probability distribution for any subset of network variables.\n",
            "\n",
            "In the context of modeling distributions, Bayesian networks are particularly useful when dealing with complex, multi-dimensional distributions or conditional probabilities. They allow us to model complex patterns in the data and make probabilistic predictions given some observed values.\n",
            "\n",
            "Neural networks, as we previously established, can also model a wide range of distributions, including non-parametric and continuous ones. However, Bayesian networks offer an additional layer of sophistication in modeling complex dependencies between variables.\n",
            "\n",
            "In light of this new context, we can update our original answer to conclude that neural networks and Bayesian networks are both capable of modeling any distribution. Neural networks can learn complex mappings from input to output distributions, while Bayesian networks provide a powerful framework for modeling conditional probabilities and complex patterns in data.\n",
            "\n",
            "Sources:\n",
            "\n",
            "* Mitchell, T. (2020). Machine Learning. Chapter 6: Bayesian Networks.\n",
            "* The original sources provided earlier remain relevant as well.\n",
            "\n",
            "Final Answer: Neural networks and Bayesian networks are both capable of modeling any distribution.Based on the additional context provided, I refined the original answer to provide a more comprehensive explanation.\n",
            "\n",
            "The original answer stated that neural networks can model complex distributions, including mixtures of Gaussian distributions. However, the new context provides insight into Bayesian networks, which are a type of probabilistic graphical model.\n",
            "\n",
            "A Bayesian network is a directed acyclic graph (DAG) where each node represents a random variable and the edges represent conditional dependencies between variables. Given observed values for only a subset of the other variables, a Bayesian network can be used to compute the probability distribution for any subset of network variables.\n",
            "\n",
            "In the context of modeling distributions, Bayesian networks are particularly useful when dealing with complex, multi-dimensional distributions or conditional probabilities. They allow us to model complex patterns in the data and make probabilistic predictions given some observed values.\n",
            "\n",
            "Neural networks, as we previously established, can also model a wide range of distributions, including non-parametric and continuous ones. However, Bayesian networks offer an additional layer of sophistication in modeling complex dependencies between variables.\n",
            "\n",
            "In light of this new context, we can update our original answer to conclude that neural networks and Bayesian networks are both capable of modeling any distribution. Neural networks can learn complex mappings from input to output distributions, while Bayesian networks provide a powerful framework for modeling conditional probabilities and complex patterns in data.\n",
            "\n",
            "Sources:\n",
            "\n",
            "* Mitchell, T. (2020). Machine Learning. Chapter 6: Bayesian Networks.\n",
            "* The original sources provided earlier remain relevant as well.\n",
            "\n",
            "Final Answer: Neural networks and Bayesian networks are both capable of modeling any distribution.FINAL OUTPUT: Based on the additional context provided, I refined the original answer to provide a more comprehensive explanation.\n",
            "\n",
            "The original answer stated that neural networks can model complex distributions, including mixtures of Gaussian distributions. However, the new context provides insight into Bayesian networks, which are a type of probabilistic graphical model.\n",
            "\n",
            "A Bayesian network is a directed acyclic graph (DAG) where each node represents a random variable and the edges represent conditional dependencies between variables. Given observed values for only a subset of the other variables, a Bayesian network can be used to compute the probability distribution for any subset of network variables.\n",
            "\n",
            "In the context of modeling distributions, Bayesian networks are particularly useful when dealing with complex, multi-dimensional distributions or conditional probabilities. They allow us to model complex patterns in the data and make probabilistic predictions given some observed values.\n",
            "\n",
            "Neural networks, as we previously established, can also model a wide range of distributions, including non-parametric and continuous ones. However, Bayesian networks offer an additional layer of sophistication in modeling complex dependencies between variables.\n",
            "\n",
            "In light of this new context, we can update our original answer to conclude that neural networks and Bayesian networks are both capable of modeling any distribution. Neural networks can learn complex mappings from input to output distributions, while Bayesian networks provide a powerful framework for modeling conditional probabilities and complex patterns in data.\n",
            "\n",
            "Sources:\n",
            "\n",
            "* Mitchell, T. (2020). Machine Learning. Chapter 6: Bayesian Networks.\n",
            "* The original sources provided earlier remain relevant as well.\n",
            "\n",
            "Final Answer: Neural networks and Bayesian networks are both capable of modeling any distribution.\n"
          ]
        }
      ],
      "source": [
        "refine_template = (\n",
        "    \"The original question is as follows: {question}\\n\"\n",
        "    \"We have provided an existing answer, including sources: {existing_answer}\\n\"\n",
        "    \"We have the opportunity to refine the existing answer\"\n",
        "    \"(only if needed) with some more context below.\\n\"\n",
        "    \"------------\\n\"\n",
        "    \"{context_str}\\n\"\n",
        "    \"------------\\n\"\n",
        "    \"Given the new context, refine the original answer to better \"\n",
        "    \"answer the question\"\n",
        "    \"If you do update it, please update the sources as well. \"\n",
        "    \"If the context isn't useful, return the original answer.\"\n",
        "    \"Only display the final answer selected after completing ALL the iterations\"\n",
        ")\n",
        "refine_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"existing_answer\", \"context_str\"],\n",
        "    template=refine_template,\n",
        ")\n",
        "\n",
        "\n",
        "question_template = (\n",
        "    \"Context information is below. \\n\"\n",
        "    \"---------------------\\n\"\n",
        "    \"{context_str}\"\n",
        "    \"\\n---------------------\\n\"\n",
        "    \"Given the context information and not prior knowledge, \"\n",
        "    \"answer the question: {question}\\n\"\n",
        ")\n",
        "question_prompt = PromptTemplate(\n",
        "    input_variables=[\"context_str\", \"question\"], template=question_template\n",
        ")\n",
        "\n",
        "query = 'can neural networks model any distribution?'\n",
        "max_iterations= 3\n",
        "chain = load_qa_with_sources_chain(\n",
        "    llm,\n",
        "    chain_type=\"refine\",\n",
        "    return_intermediate_steps=True,\n",
        "    question_prompt=question_prompt,\n",
        "    refine_prompt=refine_prompt)\n",
        "\n",
        "docs = db.similarity_search(query)\n",
        "\n",
        "response = chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)\n",
        "\n",
        "#for n,item in enumerate(response['intermediate_steps']):\n",
        "#    print(f'Step #{n}')\n",
        "#    print(item)\n",
        "#   print('\\n')\n",
        "\n",
        "print(f'FINAL OUTPUT: {response[\"output_text\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf2l_ldnqAuH"
      },
      "source": [
        "Marginal Relevance search to look at the diversity of matched responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKZ0SHWiqAuI",
        "outputId": "2643d3d7-be8e-404f-f8e0-1f2deb4f623d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mMatch 0:\u001b[0m categorized by model structure into supervised, unsupervised and reinforcement learning. With supervised ML algorithms we use labeled training data set to develop the model which\n",
            "\u001b[1mMatch 1:\u001b[0m The unsupervised learning algorithms that can be used for clustering are k-means, CURE (Clustering Using Representatives), SOM (Self-Organizing Map), Spectral clustering, LDA (Linear Discriminant Analysis). And evolutionary algorithms like genetic algorithm and particle swarm optimization is used.MACHINE LEARNING ALGORITHMS IN ONLINE TRAININGrtNEATReal-time Neuro-Evolution of Augmenting Topologies (rtNEAT) is the Neuro evolutionary algorithm\n"
          ]
        }
      ],
      "source": [
        "query='Tell me the names of the supervised algorithms in ml?Tell me the names and nothing else'\n",
        "similarity_results = db.max_marginal_relevance_search(query,k=2, fetch_k=3, lambda_mult=0.4)\n",
        "for n, item in enumerate(similarity_results):\n",
        "    print(f'\\033[1mMatch {n}:\\033[0m {item.page_content}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L29HjVrtqAuI",
        "outputId": "1f17db70-8bd4-44c8-a82d-d2ba9330f575"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YESYESYESYESDocument 0: \n",
            "19.9 Hypothesis Testing \n",
            "Source:/Users/ashmitamukherjee/Documents/NvidiaRag/data/M2-Machine_Learning_By_Ethem_Alpaydin.pdf \n",
            "Page:535 \n",
            "\n",
            "\n",
            "Document 1: \n",
            "Construct a hypothesisTesting of HypothesisThe Testing of hypothesis play a significant role in decision making in data analysis to determine whether the observed results follows certain assumption (hypothesis). \n",
            "Source:/Users/ashmitamukherjee/Documents/NvidiaRag/data/Handbook_of_Research_on_Emerging_Trends_and_Applications_of_Machine.pdf \n",
            "Page:237 \n",
            "\n",
            "\n",
            "Document 2: \n",
            "136 Chapter 9. Hypothesis testing \n",
            "Source:/Users/ashmitamukherjee/Documents/NvidiaRag/data/thinkstats2.pdf \n",
            "Page:155 \n",
            "\n",
            "\n",
            "Document 3: \n",
            "118 Chapter 9. Hypothesis testingThe goal of classical hypothesis testing is to answer the question, “Given asample and an apparent eﬀect, what is the probability of seeing such an eﬀectby chance?” Here’s how we answer that question:•The ﬁrst step is to quantify the size of the apparent eﬀect by choosing atest statistic . In the NSFG example, the apparent eﬀect is a diﬀerencein pregnancy length between ﬁrst babies and others, so a natural choice \n",
            "Source:/Users/ashmitamukherjee/Documents/NvidiaRag/data/thinkstats2.pdf \n",
            "Page:137 \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain.retrievers.document_compressors import LLMChainFilter\n",
        "compressor = LLMChainFilter.from_llm(llm)\n",
        "\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=db.as_retriever()\n",
        ")\n",
        "question = \"What do you know about hypothesis tests?\"\n",
        "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
        "\n",
        "for n, doc in enumerate(compressed_docs):\n",
        "    print(f'Document {n}: \\n{doc.page_content} \\nSource:{doc.metadata[\"source\"]} \\nPage:{doc.metadata[\"page\"]} \\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_wRtqhfqAuI"
      },
      "source": [
        "MultiQueryRetriver gives the most related queries related to the asked query!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4V5RQKTvqAuI",
        "outputId": "9063ee82-1ac7-4baa-976d-2a81663ba20c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here are three different versions of the original question:\n",
            "\n",
            "What is the concept of hypothesis testing in statistics?\n",
            "\n",
            "How do statisticians use hypothesis testing to draw conclusions about populations based on sample data?\n",
            "\n",
            "Can you explain the purpose and process of conducting a statistical test, such as a null hypothesis test, in detail?\n",
            "\n",
            "These alternative questions can help retrieve relevant documents from a vector database by capturing different aspects of the original question. For example:\n",
            "\n",
            "* The first version focuses on the concept or definition of hypothesis testing, which may retrieve documents that provide a clear explanation of the term.\n",
            "* The second version emphasizes the application of hypothesis testing in statistics, which may retrieve documents that discuss its use in drawing conclusions about populations.\n",
            "* The third version delves deeper into the process and purpose of conducting a statistical test, which may retrieve documents that provide detailed information on specific tests or their applications.\n",
            "\n",
            "By generating these alternative questions, we can increase the chances of retrieving relevant documents from the vector database that might not have been retrieved by the original question alone."
          ]
        }
      ],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "question = \"What is hypothesis tests in statistics?\"\n",
        "#llm = ChatOpenAI(temperature=0)\n",
        "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
        "    retriever=db.as_retriever(), llm=llm\n",
        ")\n",
        "mqr = retriever_from_llm.invoke(question)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lc4T6iooqAuI",
        "outputId": "55517957-1dcc-4d63-e9b0-24ccf0697977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here are three alternative versions of the original question:\n",
            "\n",
            "How do researchers utilize statistical hypothesis testing to make inferences about a larger population based on a representative sample?\n",
            "\n",
            "What statistical techniques do analysts employ to validate hypotheses about a population's characteristics using information gathered from a subset of the overall dataset?\n",
            "\n",
            "Can you provide examples or case studies illustrating how statisticians apply hypothesis testing to draw meaningful conclusions about populations, given limited data from a sample group?"
          ]
        }
      ],
      "source": [
        "retrievedDocs = await retriever_from_llm.aget_relevant_documents(\"How do statisticians use hypothesis testing to draw conclusions about populations based on sample data?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f_obJRqqAuI"
      },
      "source": [
        "RetrievalQA performs the best! However it is noticed that it doesn't have the ability to retain context which is why in the last section I have introduced ConversationalRetrievalChain for memory retention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsUiyIkzqAuI",
        "outputId": "2eb82d9e-2179-4141-d856-a7c6f69f9c92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The context is about estimating the generalization error of a machine learning model, which refers to the expected value of the error on new inputs that were not part of the training set.\n",
            "\n",
            "According to this text, the generalization error is defined as the expected value of the error on a new input. This expectation is taken across different possible inputs drawn from the distribution of inputs we expect the system to encounter in practice. The typical way to estimate the generalization error of a machine learning model is by measuring its performance on a test set that was collected separately from the training set.\n",
            "\n",
            "In this context, it seems that the authors are discussing linear regression and stochastic gradient descent (SGD) as methods for minimizing the loss function with respect to the parameters. They also mention using a minibatch of examples to compute the gradient of the loss with respect to the parameters.\n",
            "\n",
            "The generalization error can be estimated using the test set, but in some cases, this point estimate may not provide enough confidence that the model is indeed better than the current one in production. To obtain more information about the precision of this estimate, a 95% confidence interval for the generalization error can be computed using scipy.stats.t.interval().\n",
            "\n",
            "Thank you!"
          ]
        }
      ],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from pprint import pprint\n",
        "\n",
        "refine_prompt_template = \"\"\"\n",
        "You are given a question {question}\n",
        "\n",
        "Based on this question, retrieve the context and give me more than 3 sentences. If you are unsure about the answer just say I dont have this information. Say thank you after answering!\n",
        "{context}\n",
        "\"\"\"\n",
        "refine_prompt = PromptTemplate(\n",
        "    template= refine_prompt_template,\n",
        "    input_variables= ['question','context'],\n",
        ")\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm= llm,\n",
        "    retriever=new_db.as_retriever(),\n",
        "    #chain_type = 'refine',\n",
        "    chain_type_kwargs = {\"prompt\":refine_prompt}\n",
        ")\n",
        "# Pass question to the qa_chain\n",
        "question = \"What is the generalizable error?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "#result[\"result\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qu-JJeKxqAuJ",
        "outputId": "7f826cf4-58e1-4017-ca26-103bc0e4e95f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The irreducible error refers to the noisiness of the data itself. This part of the error cannot be eliminated by increasing model complexity or training on more data, but rather requires careful data cleaning, such as fixing broken sensors or removing outliers. The only way to reduce this type of error is to improve the quality of the underlying data.\n",
            "\n",
            "Thank you!"
          ]
        }
      ],
      "source": [
        "question = \"What is the irreducible error?\"\n",
        "result = qa_chain({\"query\": question})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zti47butqAuJ",
        "outputId": "c7cfab1f-3ce8-4fd1-835a-6af1c4c0c19c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on this context, I'll provide a detailed description of the Gini index:\n",
            "\n",
            "The Gini index is a measure of impurity or uncertainty in a dataset. It's used to evaluate the quality of splits made during decision tree construction. The Gini index is defined as 1 minus the sum of the squared probabilities of each class in a node, where the probability of a class is the ratio of instances belonging to that class over the total number of instances.\n",
            "\n",
            "In other words, given a dataset with n classes and m training instances, the Gini index for a particular node is calculated as:\n",
            "\n",
            "Gi = 1 - ∑k=1npi,k2 \\* pi,k\n",
            "\n",
            "where pi,k is the ratio of class k instances among the training instances in the ith node.\n",
            "\n",
            "The Gini index has several important properties. Firstly, it's maximized when classes are perfectly mixed (i.e., all classes have an equal number of instances). This means that if a decision tree splits a dataset into two child nodes with identical class distributions as the parent node, the Gini index will be maximal. Secondly, the Gini index is minimized when one class dominates the other(s) in the node. In this case, the Gini index measures the probability of misclassification.\n",
            "\n",
            "The Gini index is an intermediate measure between entropy and classification error. Entropy tries to maximize mutual information in a tree, while the Gini index attempts to minimize the probability of misclassification. This makes it a useful metric for evaluating decision trees.\n",
            "\n",
            "Thank you!"
          ]
        }
      ],
      "source": [
        "question = \"Describe Gini index\"\n",
        "result = qa_chain({\"query\": question})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz1TtmfIqAuJ"
      },
      "source": [
        " Working of ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXAJlYHXqAuJ"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "memory = ConversationBufferMemory(memory_key='history',return_messages=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukVoaT2WqAuP",
        "outputId": "39ffe879-b61c-4aaa-e1bf-681cfd8b249a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "memory1 ==> {'history': 'Human: hi\\nAI: whats up'}\n",
            "memory2 ==> {'chat_history': 'Human: hi\\nAI: whats up'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='hi'),\n",
              "  AIMessage(content='whats up'),\n",
              "  HumanMessage(content='tell me more'),\n",
              "  AIMessage(content='more'),\n",
              "  HumanMessage(content='hi'),\n",
              "  AIMessage(content='whats up'),\n",
              "  HumanMessage(content='tell me more'),\n",
              "  AIMessage(content='more')]}"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory1 = ConversationBufferMemory( memory_key=\"history\")\n",
        "memory1.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
        "print(f\"memory1 ==> {memory1.load_memory_variables({})}\")\n",
        "memory2 = ConversationBufferMemory( memory_key=\"chat_history\")\n",
        "memory2.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
        "print(f\"memory2 ==> {memory2.load_memory_variables({})}\")\n",
        "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
        "memory.save_context({\"input\": \"tell me more\"}, {\"output\": \"more\"})\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_60RaY3qAuP",
        "outputId": "0356dc70-6538-4e85-c922-4b893eb13545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi there!\n",
            "AI:\u001b[0m\n",
            "Nice to meet you! I'm glad you're initiating a chat with me. My training data consists of over 45 terabytes of text from various sources including books, articles, research papers, and websites. This extensive knowledge base allows me to provide accurate and informative responses to your queries. By the way, would you like to know more about my architecture or capabilities? I'm happy to share!\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Nice to meet you! I'm glad you're initiating a chat with me. My training data consists of over 45 terabytes of text from various sources including books, articles, research papers, and websites. This extensive knowledge base allows me to provide accurate and informative responses to your queries. By the way, would you like to know more about my architecture or capabilities? I'm happy to share!\""
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "conversation = ConversationChain (\n",
        "    llm=llm,\n",
        "    verbose = True,\n",
        "    memory = ConversationBufferMemory(memory_key='history')\n",
        ")\n",
        "conversation.predict(input=\"Hi there!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpIhgZDqqAuP"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts.prompt import PromptTemplate\n",
        "template = \"\"\"You are a education question-answering assistant , answer questions that you know properly and concisely. If you don't know please say \"I don't know\".\n",
        "Current conversation:\n",
        "{history}\n",
        "Human: {input}\n",
        "AI:\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"],\n",
        "                        template=template)\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    prompt=PROMPT,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    memory=ConversationBufferMemory(human_prefix=\"Human\")\n",
        "                                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzIikWpvqAuP",
        "outputId": "297600b5-f82c-4518-91f9-5ccfee80d390"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are a education question-answering assistant , answer questions that you know properly and concisely. If you don't know please say \"I don't know\".\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi there!\n",
            "AI:\u001b[0m\n",
            "Hi there! I'm happy to help with any educational questions you may have. What's on your mind?\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Hi there! I'm happy to help with any educational questions you may have. What's on your mind?\""
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Hi there!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLdW3CJFqAuP",
        "outputId": "41891bcb-403c-4737-e89e-ae8e33b173ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are a education question-answering assistant , answer questions that you know properly and concisely. If you don't know please say \"I don't know\".\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI: Hi there! I'm happy to help with any educational questions you may have. What's on your mind?\n",
            "Human: Do you know what is data science?\n",
            "AI:\u001b[0m\n",
            "Yes, I do! Data Science refers to the process of extracting insights and knowledge from large datasets using various techniques, including machine learning, statistical modeling, and data visualization. It involves using computational methods to analyze and interpret complex data in order to answer questions, identify patterns, and inform decision-making. Some common applications of data science include predicting customer behavior, detecting fraud, optimizing business processes, and making sense of vast amounts of data generated by sensors and other sources.\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Yes, I do! Data Science refers to the process of extracting insights and knowledge from large datasets using various techniques, including machine learning, statistical modeling, and data visualization. It involves using computational methods to analyze and interpret complex data in order to answer questions, identify patterns, and inform decision-making. Some common applications of data science include predicting customer behavior, detecting fraud, optimizing business processes, and making sense of vast amounts of data generated by sensors and other sources.'"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Do you know what is data science?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd32c2XtqAuQ"
      },
      "source": [
        "Using ConversationalRetrievalChain we can see that the it retains memory. I have asked it multiple questions about Random Forest and it has maintained the context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iv3p_E3xqAuQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a\n",
        "standalone question without changing the content in given question. Make sure that the question is answered in 3 to 4 lines. If you dont know then say I dont know. Also say thanks for asking!\n",
        "\n",
        "Chat History:\n",
        "{chat_history}\n",
        "Follow Up Input: {question}\n",
        "Standalone question:\"\"\"\n",
        "prompt_temp = PromptTemplate.from_template(template)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwW5Nfk8qAuQ",
        "outputId": "7fdaa891-68b9-4330-b122-926dd5f79df7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "Random Forest is an ensemble technique that generates many decision trees and combines them to build a more realistic and accurate model. It can be used for classification as well as regression. Using scikit-learn in python, Random Forest can be used to list the relative importance of the features in classifying the target attribute. In this work, a group of 100 decision trees is used in random forest to give a better result. Since the student dropout data is class-imbalanced, so the class_\n",
            "\n",
            "Random Forest Results Analysis on Various diseases:Random Forest is non linear ensemble classifier; we can apply on various clinical diseases identifica-tion and prediction. This algorithm used to reduce problem of over fitting. It consisting of a collection of decision trees, where each tree is constructed by applying an algorithm training dataset with an ad-ditional random vector sample.The prediction of the random forest is obtained by a majority vote over predictions of the individual\n",
            "\n",
            "Random forestIt is used to classify the objects based on the majority voting rules and ensemble of the multiple decision trees.Neural network and deep learningNeural network (NN) has layers of connected neurons which learns from with input layer, hidden layers (multiple in case of deep learning) and output layers.Support vector machineIt is a technique which draws input to high-dimensional space by constructing a set of hyperplanes through some non-linear mapping.\n",
            "\n",
            "a lower variance.Random ForestsAs we have discussed, a Random Forest9 is an ensemble of Decision Trees, generallytrained via the bagging method (or sometimes pasting), typically with max_samplesset to the size of the training set. Instead of building a BaggingClassifier  and pass‐ing it a DecisionTreeClassifier , you can instead use the RandomForestClassifierclass, which is more convenient and optimized for Decision Trees10 (similarly, there is\n",
            "\n",
            "Question: What is the use of Random Forest ?\n",
            "Helpful Answer:\u001b[0m\n",
            "According to the context, the uses of Random Forest include:\n",
            "\n",
            "* Generating many decision trees and combining them to build a more realistic and accurate model\n",
            "* Reducing the problem of over-fitting\n",
            "* Classifying objects based on majority voting rules and ensemble of multiple decision trees\n",
            "* Identifying and predicting various clinical diseases\n",
            "* Providing a list of relative importance of features in classifying the target attribute\n",
            "\n",
            "It is also mentioned that Random Forests are used to reduce variance, which suggests that it can be useful for improving model performance.\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "question_generator = LLMChain(llm=llm, prompt=prompt_temp, memory=memory)\n",
        "memory = ConversationBufferMemory(memory_key='chat_history',return_messages=True)\n",
        "retriever_qa = new_db.as_retriever()\n",
        "qa = ConversationalRetrievalChain.from_llm(llm = llm,\n",
        "                                  retriever = retriever_qa,\n",
        "                                  memory = memory,\n",
        "                                  verbose= True)\n",
        "question = \"What is the use of Random Forest ?\"\n",
        "result_1 = qa({\"question\": question})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knIC-QHCqAuQ",
        "outputId": "1d95b1c5-a1bc-454d-998b-9c3aaacd1c67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "\n",
            "Human: What is the use of Random Forest ?\n",
            "Assistant: According to the context, the uses of Random Forest include:\n",
            "\n",
            "* Generating many decision trees and combining them to build a more realistic and accurate model\n",
            "* Reducing the problem of over-fitting\n",
            "* Classifying objects based on majority voting rules and ensemble of multiple decision trees\n",
            "* Identifying and predicting various clinical diseases\n",
            "* Providing a list of relative importance of features in classifying the target attribute\n",
            "\n",
            "It is also mentioned that Random Forests are used to reduce variance, which suggests that it can be useful for improving model performance.\n",
            "Human: Can it handle missing data?\n",
            "Assistant: According to the provided context, I don't know if Random Forest can specifically handle missing data or not. The text only discusses the general workings and characteristics of Random Forests, without mentioning handling missing values.\n",
            "Human: What are its important hyperparameters?\n",
            "Assistant: Based on the provided context, some key hyperparameters for Random Forest include:\n",
            "\n",
            "* n_estimators (number of trees in the forest)\n",
            "* max_features (maximum number of features to consider at each split)\n",
            "\n",
            "Additionally, it is mentioned that other hyperparameters can be optimized, including:\n",
            "\n",
            "* The size n of the bootstrap sample\n",
            "* The number of features d randomly chosen for each split\n",
            "Follow Up Input: What are its important hyperparameters? Give me around 5\n",
            "Standalone question:\u001b[0m\n",
            "Here is the rephrased follow-up question as a standalone question in its original language:\n",
            "\n",
            "What are some key hyperparameters of Random Forest, and can you name at least 4 of them?\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "in Chapter 7 ), then try all 2 × 3 = 6 combinations of hyperparameter values in thesecond dict , but this time with the bootstrap  hyperparameter set to False  instead ofTrue  (which is the default value for this hyperparameter).All in all, the grid search will explore 12 + 6 = 18 combinations of RandomForestRegressor  hyperparameter values, and it will train each model five times (since we areusing five-fold cross validation). In other words, all in all, there will be 18 × 5 = 90\n",
            "\n",
            "nation of hyperparameter values for the RandomForestRegressor :from sklearn.model_selection  import GridSearchCVparam_grid  = [    {'n_estimators' : [3, 10, 30], 'max_features' : [2, 4, 6, 8]},    {'bootstrap' : [False], 'n_estimators' : [3, 10], 'max_features' : [2, 3, 4]},  ]forest_reg  = RandomForestRegressor ()grid_search  = GridSearchCV (forest_reg , param_grid , cv=5,                           scoring='neg_mean_squared_error' ,                           return_train_score =True)\n",
            "\n",
            "Diﬀerent HyperparametersWe can use the same learning algorithm but use it with diﬀerent hyper-parameters. Examples are the number of hidden units in a multilayer\n",
            "\n",
            "Chapter 3[ 91 ]Although it is less common in practice, other hyperparameters of the random  forest classifier that can be optimized—using techniques we will discuss in  Chapter 5 , Compressing Data via Dimensionality Reduction —are the size n  of the bootstrap sample (step 1) and the number of features d that is randomly  chosen for each split (step 2.1), respectively. Via the sample size n of the bootstrap sample, we control the bias-variance tradeoff of the random forest. By choosing\n",
            "\n",
            "Question: Here is the rephrased follow-up question as a standalone question in its original language:\n",
            "\n",
            "What are some key hyperparameters of Random Forest, and can you name at least 4 of them?\n",
            "Helpful Answer:\u001b[0m\n",
            "Based on the provided context, I can identify four key hyperparameters of Random Forest:\n",
            "\n",
            "1. `n_estimators`: The number of decision trees to combine.\n",
            "2. `max_features`: The maximum number of features considered for each split.\n",
            "3. `bootstrap`: A boolean indicating whether bootstrap sampling should be used or not (default is True).\n",
            "4. `max_depth`: The maximum depth of the tree, which controls overfitting.\n",
            "\n",
            "Please note that these are specific to the context and might not exhaustively cover all possible hyperparameters.\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "question = \"What are its important hyperparameters? Give me around 5\"\n",
        "result_2 = qa({\"question\": question})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQbCMZWkqAuQ",
        "outputId": "3e269bae-4dbc-4adb-8054-dd3d1fecfb10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "\n",
            "Human: What is the use of Random Forest ?\n",
            "Assistant: According to the context, the uses of Random Forest include:\n",
            "\n",
            "* Generating many decision trees and combining them to build a more realistic and accurate model\n",
            "* Reducing the problem of over-fitting\n",
            "* Classifying objects based on majority voting rules and ensemble of multiple decision trees\n",
            "* Identifying and predicting various clinical diseases\n",
            "* Providing a list of relative importance of features in classifying the target attribute\n",
            "\n",
            "It is also mentioned that Random Forests are used to reduce variance, which suggests that it can be useful for improving model performance.\n",
            "Human: Can it handle missing data?\n",
            "Assistant: According to the provided context, I don't know if Random Forest can specifically handle missing data or not. The text only discusses the general workings and characteristics of Random Forests, without mentioning handling missing values.\n",
            "Human: What are its important hyperparameters?\n",
            "Assistant: Based on the provided context, some key hyperparameters for Random Forest include:\n",
            "\n",
            "* n_estimators (number of trees in the forest)\n",
            "* max_features (maximum number of features to consider at each split)\n",
            "\n",
            "Additionally, it is mentioned that other hyperparameters can be optimized, including:\n",
            "\n",
            "* The size n of the bootstrap sample\n",
            "* The number of features d randomly chosen for each split\n",
            "Human: What are its important hyperparameters? Give me around 5\n",
            "Assistant: Based on the provided context, I can identify four key hyperparameters of Random Forest:\n",
            "\n",
            "1. `n_estimators`: The number of decision trees to combine.\n",
            "2. `max_features`: The maximum number of features considered for each split.\n",
            "3. `bootstrap`: A boolean indicating whether bootstrap sampling should be used or not (default is True).\n",
            "4. `max_depth`: The maximum depth of the tree, which controls overfitting.\n",
            "\n",
            "Please note that these are specific to the context and might not exhaustively cover all possible hyperparameters.\n",
            "Follow Up Input: What kind of data does it work with?\n",
            "Standalone question:\u001b[0m\n",
            "What types of data can Random Forest work with?\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "In-Depth: Decision Trees and Random Forests | 423\n",
            "\n",
            "Ensembles of Estimators: Random Forests                                                            426Random Forest Regression                                                                                       428Example: Random Forest for Classifying Digits                                                    430Summary of Random Forests                                                                                   432\n",
            "\n",
            "Random Forest is an ensemble technique that generates many decision trees and combines them to build a more realistic and accurate model. It can be used for classification as well as regression. Using scikit-learn in python, Random Forest can be used to list the relative importance of the features in classifying the target attribute. In this work, a group of 100 decision trees is used in random forest to give a better result. Since the student dropout data is class-imbalanced, so the class_\n",
            "\n",
            "series of yes/no questions that ends in a decision. A random forest is a collec-tion of randomly generated decision tr ees that favors trees and branches thatcorrectly classify data points. This is my go-to machine learning method when Iknow I want machine learning but I don’t have a good reason to choose a differ-ent one. It’s versatile and not to o difficult to diagnose problems.Support vector machine (SVM) —This was quite popular a few years ago, and now it\n",
            "\n",
            "Question: What types of data can Random Forest work with?\n",
            "Helpful Answer:\u001b[0m\n",
            "According to the context, Random Forest can be used for both classification as well as regression, which suggests that it is suitable for working with categorical (yes/no) or continuous data.\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "question = \"What kind of data does it work with?\"\n",
        "result_2 = qa({\"question\": question})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtBDEp5_qAuQ",
        "outputId": "779d2446-28b6-46de-8280-90e3e4c37c28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "\n",
            "Human: What is the use of Random Forest ?\n",
            "Assistant: According to the context, the uses of Random Forest include:\n",
            "\n",
            "* Generating many decision trees and combining them to build a more realistic and accurate model\n",
            "* Reducing the problem of over-fitting\n",
            "* Classifying objects based on majority voting rules and ensemble of multiple decision trees\n",
            "* Identifying and predicting various clinical diseases\n",
            "* Providing a list of relative importance of features in classifying the target attribute\n",
            "\n",
            "It is also mentioned that Random Forests are used to reduce variance, which suggests that it can be useful for improving model performance.\n",
            "Human: Can it handle missing data?\n",
            "Assistant: According to the provided context, I don't know if Random Forest can specifically handle missing data or not. The text only discusses the general workings and characteristics of Random Forests, without mentioning handling missing values.\n",
            "Human: What are its important hyperparameters?\n",
            "Assistant: Based on the provided context, some key hyperparameters for Random Forest include:\n",
            "\n",
            "* n_estimators (number of trees in the forest)\n",
            "* max_features (maximum number of features to consider at each split)\n",
            "\n",
            "Additionally, it is mentioned that other hyperparameters can be optimized, including:\n",
            "\n",
            "* The size n of the bootstrap sample\n",
            "* The number of features d randomly chosen for each split\n",
            "Human: What are its important hyperparameters? Give me around 5\n",
            "Assistant: Based on the provided context, I can identify four key hyperparameters of Random Forest:\n",
            "\n",
            "1. `n_estimators`: The number of decision trees to combine.\n",
            "2. `max_features`: The maximum number of features considered for each split.\n",
            "3. `bootstrap`: A boolean indicating whether bootstrap sampling should be used or not (default is True).\n",
            "4. `max_depth`: The maximum depth of the tree, which controls overfitting.\n",
            "\n",
            "Please note that these are specific to the context and might not exhaustively cover all possible hyperparameters.\n",
            "Human: What kind of data does it work with?\n",
            "Assistant: According to the context, Random Forest can be used for both classification as well as regression, which suggests that it is suitable for working with categorical (yes/no) or continuous data.\n",
            "Human: Name some other emsemble methods and which is the best compared to the one mentioned before?\n",
            "Assistant: According to the provided context, besides Random Forest, some other ensemble learning approaches mentioned include:\n",
            "\n",
            "1. Bagging\n",
            "2. Adaboost\n",
            "3. Ensemble classifiers (which combines three heterogeneous classifiers: random forest, logistic regression, and sequential minimal optimization)\n",
            "\n",
            "These are explicitly mentioned in the text as being used for classification tasks.\n",
            "Human: Name some other emsemble methods and which is the best compared to the one mentioned before?\n",
            "Assistant: According to the provided context, besides Bagging (which was mentioned earlier as an example), there is also AdaBoost, which is another type of ensemble learning approach. Additionally, the text mentions that a multi-layer model combines three heterogeneous classifiers: random forest, logistic regression, and sequential minimal optimization approaches for classification.\n",
            "\n",
            "It's worth noting that these are the only specific examples provided in the given context. If you're looking for more comprehensive information on various ensemble learning approaches beyond what is mentioned here, I would recommend consulting external sources or resources (e.g., academic papers, tutorials, etc.).\n",
            "Follow Up Input: what is the algorithm of this model?\n",
            "Standalone question:\u001b[0m\n",
            "What is the algorithm used in Random Forest?\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "more robust model, a strong learner , that has a better generalization error and is less susceptible to overfitting. The random forest algorithm can be summarized in four simple steps:1. Draw a random bootstrap  sample of size n (randomly choose n samples from the training set with replacement).2. Grow a decision tree from the bootstrap sample. At each node:1. Randomly select d features without replacement.2. Split the node using the feature that provides the best split\n",
            "\n",
            "In-Depth: Decision Trees and Random ForestsPreviously we have looked in depth at a simple generative classifier (naive Bayes; see“In Depth: Naive Bayes Classification” on page 382) and a powerful discriminativeclassifier (support vector machines; see “In-Depth: Support Vector Machines” onpage 405). Here we’ll take a look at motivating another powerful algorithm—a non‐parametric algorithm called random forests . Random forests are an example of an\n",
            "\n",
            "high-dimensional datasets. The algorithm builds a Random Forest in which eachDecision Tree is grown randomly: at each node, it picks a feature randomly, thenit picks a random threshold value (between the min and max value) to split thedataset in two. The dataset gradually gets chopped into pieces this way, until allinstances end up isolated from the other instances. An anomaly is usually farfrom other instances, so on average (across all the Decision Trees) it tends to get\n",
            "\n",
            "DecisionTreeClassifier  (to control how trees are grown), plus all the hyperpara‐meters of a BaggingClassifier  to control the ensemble itself.11The Random Forest algorithm introduces extra randomness when growing trees;instead of searching for the very best feature when splitting a node (see Chapter 6 ), itsearches for the best feature among a random subset of features. This results in agreater tree diversity, which (once again) trades a higher bias for a lower variance,\n",
            "\n",
            "Question: What is the algorithm used in Random Forest?\n",
            "Helpful Answer:\u001b[0m\n",
            "The helpful answer to this question would be that the algorithm used in Random Forests is decision trees with random feature selection. This means that at each node, instead of selecting the best feature based on some metric (such as Gini impurity or information gain), a subset of features are randomly selected and the one that provides the best split is chosen.\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "question = \"what is the algorithm of this model?\"\n",
        "result_3 = qa({\"question\": question})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2td9SqfFqAuQ",
        "outputId": "2a817c13-4aeb-4ccd-ff3e-bb8b33770c78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'what is the algorithm of this model?',\n",
              " 'chat_history': [HumanMessage(content='What is the use of Random Forest ?'),\n",
              "  AIMessage(content='According to the context, the uses of Random Forest include:\\n\\n* Generating many decision trees and combining them to build a more realistic and accurate model\\n* Reducing the problem of over-fitting\\n* Classifying objects based on majority voting rules and ensemble of multiple decision trees\\n* Identifying and predicting various clinical diseases\\n* Providing a list of relative importance of features in classifying the target attribute\\n\\nIt is also mentioned that Random Forests are used to reduce variance, which suggests that it can be useful for improving model performance.'),\n",
              "  HumanMessage(content='Can it handle missing data?'),\n",
              "  AIMessage(content=\"According to the provided context, I don't know if Random Forest can specifically handle missing data or not. The text only discusses the general workings and characteristics of Random Forests, without mentioning handling missing values.\"),\n",
              "  HumanMessage(content='What are its important hyperparameters?'),\n",
              "  AIMessage(content='Based on the provided context, some key hyperparameters for Random Forest include:\\n\\n* n_estimators (number of trees in the forest)\\n* max_features (maximum number of features to consider at each split)\\n\\nAdditionally, it is mentioned that other hyperparameters can be optimized, including:\\n\\n* The size n of the bootstrap sample\\n* The number of features d randomly chosen for each split'),\n",
              "  HumanMessage(content='What are its important hyperparameters? Give me around 5'),\n",
              "  AIMessage(content='Based on the provided context, I can identify four key hyperparameters of Random Forest:\\n\\n1. `n_estimators`: The number of decision trees to combine.\\n2. `max_features`: The maximum number of features considered for each split.\\n3. `bootstrap`: A boolean indicating whether bootstrap sampling should be used or not (default is True).\\n4. `max_depth`: The maximum depth of the tree, which controls overfitting.\\n\\nPlease note that these are specific to the context and might not exhaustively cover all possible hyperparameters.'),\n",
              "  HumanMessage(content='What kind of data does it work with?'),\n",
              "  AIMessage(content='According to the context, Random Forest can be used for both classification as well as regression, which suggests that it is suitable for working with categorical (yes/no) or continuous data.'),\n",
              "  HumanMessage(content='Name some other emsemble methods and which is the best compared to the one mentioned before?'),\n",
              "  AIMessage(content='According to the provided context, besides Random Forest, some other ensemble learning approaches mentioned include:\\n\\n1. Bagging\\n2. Adaboost\\n3. Ensemble classifiers (which combines three heterogeneous classifiers: random forest, logistic regression, and sequential minimal optimization)\\n\\nThese are explicitly mentioned in the text as being used for classification tasks.'),\n",
              "  HumanMessage(content='Name some other emsemble methods and which is the best compared to the one mentioned before?'),\n",
              "  AIMessage(content=\"According to the provided context, besides Bagging (which was mentioned earlier as an example), there is also AdaBoost, which is another type of ensemble learning approach. Additionally, the text mentions that a multi-layer model combines three heterogeneous classifiers: random forest, logistic regression, and sequential minimal optimization approaches for classification.\\n\\nIt's worth noting that these are the only specific examples provided in the given context. If you're looking for more comprehensive information on various ensemble learning approaches beyond what is mentioned here, I would recommend consulting external sources or resources (e.g., academic papers, tutorials, etc.).\"),\n",
              "  HumanMessage(content='what is the algorithm of this model?'),\n",
              "  AIMessage(content='The helpful answer to this question would be that the algorithm used in Random Forests is decision trees with random feature selection. This means that at each node, instead of selecting the best feature based on some metric (such as Gini impurity or information gain), a subset of features are randomly selected and the one that provides the best split is chosen.')],\n",
              " 'answer': 'The helpful answer to this question would be that the algorithm used in Random Forests is decision trees with random feature selection. This means that at each node, instead of selecting the best feature based on some metric (such as Gini impurity or information gain), a subset of features are randomly selected and the one that provides the best split is chosen.'}"
            ]
          },
          "execution_count": 184,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_3"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}